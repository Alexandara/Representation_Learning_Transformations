{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time, sleep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "import math \n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variables & GPU/CPU handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 10000\n",
    "learning_rate = 1.75e-3\n",
    "\n",
    "bottleneck_size = 64\n",
    "net_size = 324\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = 'float32' if use_cuda else 'float64'\n",
    "torchtype = {'float32': torch.float32, 'float64': torch.float64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Class\n",
    "10 layers total\n",
    "- 784 (original flattened 28x28)  -> 324\n",
    "- 324 -> 256\n",
    "- 256 -> 121\n",
    "- 121 -> 81\n",
    "- 81 -> 64\n",
    "- 64 -> 81\n",
    "- 81 -> 121\n",
    "- 121 -> 256\n",
    "- 256 -> 324\n",
    "- 324 -> 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features=net_size\n",
    "        )\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=net_size, out_features=256\n",
    "        )\n",
    "        self.extra_one_layer = nn.Linear(\n",
    "            in_features=256, out_features=121\n",
    "        )\n",
    "        #\"\"\"\n",
    "        self.extra_bufferone_layer = nn.Linear(\n",
    "            in_features=121, out_features=81\n",
    "        )\n",
    "        #\"\"\"\n",
    "        self.extra_two_layer = nn.Linear( #This is latent representation 8x8\n",
    "            in_features=81, out_features=bottleneck_size\n",
    "        )\n",
    "        self.extra_three_layer = nn.Linear(\n",
    "            in_features=bottleneck_size, out_features=81\n",
    "        )\n",
    "        #\"\"\"\n",
    "        self.extra_buffertwo_layer = nn.Linear(\n",
    "            in_features=81, out_features=121\n",
    "        )\n",
    "        #\"\"\"\n",
    "        self.extra_four_layer = nn.Linear(\n",
    "            in_features=121, out_features=256\n",
    "        )\n",
    "        self.decoder_hidden_layer = nn.Linear(\n",
    "            in_features=256, out_features=net_size\n",
    "        )\n",
    "        self.decoder_output_layer = nn.Linear(\n",
    "            in_features=net_size, out_features=kwargs[\"input_shape\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "\n",
    "        activation = self.encoder_output_layer(activation)\n",
    "        activation = torch.relu(activation)\n",
    "\n",
    "\n",
    "        activation = self.extra_one_layer(activation)\n",
    "        activation = torch.relu(activation)\n",
    "\n",
    "        #\"\"\"\n",
    "        activation = self.extra_bufferone_layer(activation)\n",
    "        activation = torch.relu(activation)\n",
    "        #\"\"\"\n",
    "\n",
    "        code1 = self.extra_two_layer(activation)\n",
    "        activation = torch.relu(code1)\n",
    "\n",
    "        activation = self.extra_three_layer(activation)\n",
    "        activation = torch.relu(activation)\n",
    "\n",
    "        #\"\"\"\n",
    "        activation = self.extra_buffertwo_layer(activation)\n",
    "        activation = torch.relu(activation)\n",
    "        #\"\"\"\n",
    "\n",
    "        activation = self.extra_four_layer(activation)\n",
    "        activation = torch.relu(activation)\n",
    "\n",
    "        activation = self.decoder_hidden_layer(activation)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "\n",
    "        return reconstructed, code1\n",
    "\n",
    "def bench_k_means(estimator, name, data):\n",
    "    #t0 = time()\n",
    "    estimator.fit(data)\n",
    "    \"\"\"\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))\n",
    "                                      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run snippet below to train network\n",
    "\n",
    "data = data[1:x] \n",
    "\n",
    "change x to get a larger set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 10000/10000 [02:12<00:00, 75.47it/s, recon loss=248.68477631]\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "data = np.load(\"training_data.npy\",allow_pickle=True)\n",
    "shuffle(data)#shuffles data (very fast)\n",
    "end = time()\n",
    "# data[0] = image and labels\n",
    "# data[0][0] = image\n",
    "# data[0][1] = one hot array with labels\n",
    "# data[0][0][0] = one line of image\n",
    "data = data[1:1000]\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "#train_dataset = torchvision.datasets.MNIST(root=\"~/torch_datasets\", train=True, transform=transform, download=True)\n",
    "training_dataset = []\n",
    "for i in range(int(len(data)-(len(data)/5))): #80% of data is training\n",
    "    training_dataset.append(data[i][0])\n",
    "train_dataset = torch.Tensor(list(training_dataset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=784).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "pbar = tqdm(range(epochs))\n",
    "for epoch in pbar:\n",
    "    loss = 0\n",
    "    for batch_features in train_loader: #Used to have ,_ in front of batch_features\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute reconstructions\n",
    "        outputs, _ = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features).to(device)\n",
    "\n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    # compute the epoch training loss\n",
    "    loss = (loss / len(train_loader))\n",
    "\n",
    "    # display the epoch training loss\n",
    "    pbar.set_postfix({'recon loss': \"{:.8f}\".format(loss)})\n",
    "    #print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs, loss))\n",
    "\n",
    "#test_dataset = torchvision.datasets.MNIST(\n",
    " #   root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "#print(int((len(data)/5)*4))\n",
    "#print(len(data))\n",
    "for i in range(int((len(data)/5)*4),len(data)): #last 20% of data is test\n",
    "    #for j in range(len(data[i][0])):\n",
    "    test_dataset.append(data[i][0])\n",
    "test_dataset = torch.Tensor(list(test_dataset))\n",
    "#print(len(test_dataset))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "test_example = None\n",
    "test_examples = []\n",
    "reconstruction_examples = []\n",
    "k_representations = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features in test_loader:\n",
    "        batch_feature = batch_features[0]\n",
    "        test_example = batch_feature.view(-1, 784).to(device)\n",
    "        reconstruction, representation = model(test_example)\n",
    "        test_examples.append(batch_features[0])\n",
    "        reconstruction_examples.append(reconstruction.cpu().numpy().reshape(28,28))\n",
    "        k_representations.append(representation.cpu().numpy().reshape(int(math.sqrt(bottleneck_size)),int(math.sqrt(bottleneck_size))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run below to get samples of your test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a040c52e97dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mPulls\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#number of images to display at once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GET 3 RANDOM SETS OF ORIGINAL / LATENT / RECONSTRUCTION\n",
    "Pulls from test set\n",
    "\"\"\"\n",
    "with torch.no_grad():\n",
    "    \n",
    "    #number of images to display at once\n",
    "    #3 fits nicely on my jupyter notebook\n",
    "    number = 3\n",
    "    \n",
    "    #initialize randomness in pulling images\n",
    "    random.seed(a=None, version=2)\n",
    "    i_offset = random.randint(0, len(test_examples)-number)\n",
    "    \n",
    "    #formatting\n",
    "    plt.figure(figsize=(21, 21))\n",
    "    plt.subplots_adjust(wspace=0.0,hspace=0.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    for index in range(number):\n",
    "        # display original\n",
    "        ax = plt.subplot(3, number,index+1)\n",
    "        plt.imshow(test_examples[index+i_offset].numpy().reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display hidden layer?\n",
    "        ax = plt.subplot(3, number,index + 1*number+1)\n",
    "        plt.imshow(k_representations[index+i_offset])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(3, number, index +  2*number+1 )\n",
    "        plt.imshow(reconstruction_examples[index+i_offset])\n",
    "        plt.gray()\n",
    "        \n",
    "        #display loss under each picture\n",
    "        ax.set_xlabel(\"Loss:\"+str(criterion(torch.from_numpy(reconstruction_examples[index]),torch.from_numpy(test_examples[index].numpy().reshape(28,28))).item()),fontsize=18)\n",
    "        \n",
    "        #Hide x-axis ticks\n",
    "        ax.axes.xaxis.set_ticks([])\n",
    "        \n",
    "        #ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        #print(\"Loss:\"+str(criterion(torch.from_numpy(reconstruction_examples[index]),torch.from_numpy(test_examples[index].numpy().reshape(28,28))).item()))\n",
    "\n",
    "    plt.show() # UNCOMMENT TO VIEW AUTOENCODER EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_size = 200\n",
    "n_classes = 2\n",
    "\n",
    "\n",
    "nsamples, nx, ny = np.array(k_representations, dtype=np.double).shape\n",
    "d2_k_representations = np.array(k_representations, dtype=np.double).reshape((nsamples,nx*ny))\n",
    "\n",
    "data = scale(d2_k_representations)\n",
    "\"\"\"\n",
    "bench_k_means(KMeans(init='k-means++', n_clusters=n_classes, n_init=2),\n",
    "          name=\"k-means++\", data=data)\n",
    "\n",
    "pca = PCA(n_components=n_classes).fit(data)\n",
    "bench_k_means(KMeans(init=pca.components_, n_clusters=n_classes, n_init=1),\n",
    "          name=\"PCA-based\",\n",
    "          data=data)\n",
    "\"\"\"\n",
    "# #############################################################################\n",
    "# Visualize the results on PCA-reduced data\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_classes, n_init=2)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        cmap=plt.cm.Paired,\n",
    "        aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('K-means clustering on the MNIST-fashion dataset (PCA-reduced data)\\n'\n",
    "        'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
